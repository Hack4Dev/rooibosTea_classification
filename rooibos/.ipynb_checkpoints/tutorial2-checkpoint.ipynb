{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "100e0d5e-62fc-42dd-81f0-93a20b99dbac",
   "metadata": {},
   "source": [
    "# Tutorial 2: Data correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eaf3f6-25af-4565-8dc7-d1a1be81892b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1c3a95-ce86-495e-8d8d-e8da2cc478d6",
   "metadata": {},
   "source": [
    "### Welcome back! Congratulations for making it this far!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9096c03",
   "metadata": {},
   "source": [
    "This tutorial shows how to do a correlation analysis in Python. In particular, we will investigate correlations between the 3 features (measurements) made with water as solvent and similarly between the features with methanol as solvent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3993aed0",
   "metadata": {},
   "source": [
    "What is correlation analysis?\n",
    "\n",
    "- A statistical method which is often used to determine the degree of linear dependency between pairs of variables. \n",
    "- The dependency is expressed using a single number (the _correlation coefficient_) which is between -1 and 1. We can say that two variables are negatively correlated, positively correlated, or uncorrelated according to whether the correlation coefficient is negative, positive, or 0.\n",
    "- Two variables are strongly correlated if a scatter plot of the variables has points which lie nearly along a line. On the other hand, variables are uncorrelated is the scatter plot shows a \"cloud\" of points that has no slant tendency.\n",
    "- (You may Google \"correlation scatter plot\" to see examples of scatter plots of variable pairs with different degrees of correlation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab5c88",
   "metadata": {},
   "source": [
    "### Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff304bfb",
   "metadata": {},
   "source": [
    "First, retrieve the data from the previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e636164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 1___\n",
    "\n",
    "# Nonfermented, fermented, and combined dataframes\n",
    "%store -r df_nf\n",
    "%store -r df_fer\n",
    "%store -r df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca4f203-1d57-473e-b548-b3b028872726",
   "metadata": {},
   "source": [
    "---\n",
    "**Exercise 1:** Verify the data in the above data frames\n",
    "<br>\n",
    "_(Hint: Remember the 'head' command)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- code here -----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48049067",
   "metadata": {},
   "source": [
    "Since we will be doing more detailed data analysis, we will use the 'numpy' package ('numpy' stands for 'numerical python'). We will also use a customized code that draws _confidence ellipses_ (which we will explain below). The customized code may be found in the `sources` directory.`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21662b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 2___\n",
    "import numpy as np # 'np' is the prefix that will identify nump packages\n",
    "from source.ellipses import draw_confidence_ellipse # for representing the correlation (for\n",
    "# code see 'source' directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547df38",
   "metadata": {},
   "source": [
    "In our case, we want to compare bivariate distributions for two different datasets: \"bivariate\" refers to the fact that we are looking at the joint distributions for two different features.  \n",
    "\n",
    "To make an effective comparison, first we make 2-d scatterplots for the two datasets on the same axes. The two axes correspond to the two features being represented. The scatterplot looks like a \"cloud\" of points, where  each point corresponds to one tea sample: the $x$ and $y$ coordinates of a point are given by the values of the two features for that particular sample. \n",
    "\n",
    "In order to characterize the overall distribution, confidence ellipses are superimposed on the scatterplots for each dataset.  A confidence ellipse shows where the data is most heavily concentrated (i.e. where the probability density is highest).  Confidence regions are used for predicting new observations with a certain degree of confidence, which depends on the confidence parameter (measured in standard deviations) used to generate the ellipse. When the confidence parameter is 2, roughly 95 percent of the data lies within the confidence ellipse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c0a0fa",
   "metadata": {},
   "source": [
    "The syntax for the `draw_confidence_ellipse` command is as follows:\n",
    "\n",
    "     draw_confidence_ellipse (data1_x, data1_y, data2_x, data2_y, confidence_parameter,\n",
    "         \"x-axis label\", \"y-axis label\", \"title\", x-scale, y-scale)\"\n",
    "         \n",
    "Notice that we can continue Python commands on multiple lines, as long as we break the statement in such a way that the Python compiler can see that the command is not yet finished. A good way to do this is to make the break after an open parenthesis or bracket, or after a commma that separates items in a list.\n",
    "\n",
    "Let's give this a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f675b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 3___\n",
    "\n",
    "draw_confidence_ellipse ( \n",
    "    df_fer[['TPC_MEOH']],  df_fer[['TEAC_MEOH']],  \n",
    "    df_nf[['TPC_MEOH']],  df_nf[['TEAC_MEOH']], 2, \n",
    "    \"TPC(GAE/g)\", \"TEAC(TE/g)\", \n",
    "    \"TEAC versus TP for $MeOH$ extracted samples\",\n",
    "    [100, 550], [1000,5550] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f07a02a",
   "metadata": {},
   "source": [
    "The function draw_confidence_ellipse also gives the estimated correlation coefficient between the two variables; error denotes the uncertainty in the correlation coefficient; and p denotes the p-value for the null hypothesis that the correlation coefficient is 0 (typically the null hypothesis is denoted as  ð»0 .\n",
    "\n",
    "The p value has the following meaning (one must be very careful about this, because the p value is often misunderstood). Suppose the estimated correlation coefficient is C. In this case, the p value is the conditional probability given that the correlation coefficient is 0 that the measured correlation coefficient will have absolute value greater than or equal to C. In other words, the p value is the probability given that  ð»0  is true that a measurement that is \"at least as extreme\" as C is obtained. So it is not true that \"the p value is the probability that H0 is false\", because it is calculated under the assumption that H0 is true! Instead, the p value expresses a likelihood. For example, suppose my friend flips a coin 20 times and get 20 heads. If the coin is actually fair, the probability this would happens is less than 0.00001. So it is likely that the coin is not fair (e.g. maybe it has 'head' on both sides). But it is not correct to say that the probability that the coin is fair is 0.00001.\n",
    "\n",
    "If the p value is below a certain level, then we reject the null hypothesis. The level of rejection is called the confidence level. What significance level you use depends on the application. In many cases, a confidence level of 0.01 is used.\n",
    "\n",
    "The results show there is a statistically significant positive correlation between TPC and TEAC for fermented (blue). This is reflected in the tilted orientation of the ellipse. On the other hand, the correlation between TPC and TEAC for unfermented is not statistically signficant (p > 0.01). \n",
    "\n",
    "The graph also shows a large overlap between the fermented and nonfermented data. Both confidence ellipses contain many points with $225 < TPC < 300$ and $2000 < TEAC < 2500$. Because of the correlation, fermented data with lower values of TPC also tend to have lower values of TEAC. The relative sizes of the ellipses shows that nonfermented data is more spead out, meaning a wider range of values is observed (particularly with TPC).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e10eb",
   "metadata": {},
   "source": [
    "Now let's do the same thing for TPC vs FRAP using the methanol solvent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d541a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 4___\n",
    "\n",
    "draw_confidence_ellipse (\n",
    "    df_fer[['TPC_MEOH']], df_fer[['FRAP_MEOH']], \n",
    "    df_nf[['TPC_MEOH']], df_nf[['FRAP_MEOH']], \n",
    "    \"TPC(GAE/g)\", \"FRAP(AAE/g)\", \n",
    "    \"FRAP versus TP for $MeOH$ extracted samples\", \n",
    "    [100, 550], [1000,5550] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0dd2ca-9fb9-42fd-8c32-c19cffed2b21",
   "metadata": {},
   "source": [
    "---\n",
    "**Exercise 2:** What do the numerical results indicate about the correlations?\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923db9af-983c-4476-b162-d9816d9c6806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- answer here -----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1025c7",
   "metadata": {},
   "source": [
    "Evidently the y-scale is off, so we will need to change the scale.  To do this, we find the min and max values for FRAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9cdb4-0c50-4264-a52a-591f40eb7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 5___\n",
    "print(df_fer[['FRAP_MEOH']].min()[0]) # returns an array, and we are just interested in the first index (the actual value)\n",
    "print(\"FRAP min (fer): \" +str( df_fer[['FRAP_MEOH']].min()[0]) )\n",
    "print(\"FRAP min (nf): \" +str( df_nf[['FRAP_MEOH']].min()[0]) )\n",
    "print() # creates a space\n",
    "print(\"FRAP max (fer): \" +str( df_fer[['FRAP_MEOH']].max()[0]) )\n",
    "print(\"FRAP max (nf): \" +str( df_nf[['FRAP_MEOH']].max()[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd0e78-8a5e-40ce-bc45-2ca0ff84c193",
   "metadata": {},
   "source": [
    "---\n",
    "**Exercise 3:** Based on the above results, change the **y** scale so that both ellipses are contained in the plot. \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb23081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- code here -----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba500474",
   "metadata": {},
   "source": [
    "---\n",
    "**Exercise 4:** Create scatter & confidence ellipse plots for  the remaining variable comparison for MeOH, and for the three variable comparisons for extracts using water (H2O) as solvent. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e90bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- code here ----- (create as many new cells as you want)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158d84b3-4e6c-48b2-be40-f73bc939533c",
   "metadata": {},
   "source": [
    "**Congratulations!** You've finished analyzing the data. In the next notebook, we'll learn how to classify the rooibos data using a simple statistical method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
